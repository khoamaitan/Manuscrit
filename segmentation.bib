@inproceedings{cremers_variational_2003,
	title = {Variational space-time motion segmentation},
	isbn = {978-0-7695-1950-0},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1238442},
	doi = {10.1109/ICCV.2003.1238442},
	urldate = {2016-05-12},
	publisher = {IEEE},
	author = {{Cremers} and {Soatto}},
	year = {2003},
	pages = {886--893 vol.2}
}



@inproceedings{weiss_unified_1996,
	title = {A unified mixture framework for motion segmentation: incorporating spatial coherence and estimating the number of models},
	shorttitle = {A unified mixture framework for motion segmentation},
	doi = {10.1109/CVPR.1996.517092},
	abstract = {Describing a video sequence in terms of a small number of coherently moving segments is useful for tasks ranging from video compression to event perception. A promising approach is to view the motion segmentation problem in a mixture estimation framework. However, existing formulations generally use only the motion, data and thus fail to make use of static cues when segmenting the sequence. Furthermore, the number of models is either specified in advance or estimated outside the mixture model framework. In this work we address both of these issues. We show how to add spatial constraints to the mixture formulations and present a variant of the EM algorithm that males use of both the form and the motion constraints. Moreover this algorithm estimates the number of segments given knowledge about the level of model failure expected in the sequence. The algorithm's performance is illustrated on synthetic and real image sequences},
	booktitle = {Proceedings {CVPR} '96, 1996 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 1996},
	author = {Weiss, Y. and Adelson, E. H.},
	month = jun,
	year = {1996},
	keywords = {coherently moving segments, Computer vision, event perception, Fluid flow measurement, Image motion analysis, image segmentation, image sequences, Layout, mixture formulations, motion constraints, motion estimation, motion segmentation, Noise figure, Noise measurement, Optical noise, spatial coherence, unified mixture framework, video compression, video sequence},
	pages = {321--326},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\MAI\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8h4pxrbr.default\\zotero\\storage\\H5RDGXJX\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\MAI\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8h4pxrbr.default\\zotero\\storage\\7P4UIKCN\\Weiss and Adelson - 1996 - A unified mixture framework for motion segmentatio.pdf:application/pdf}
}

@inproceedings{weiss_smoothness_1997,
	title = {Smoothness in layers: {Motion} segmentation using nonparametric mixture estimation},
	shorttitle = {Smoothness in layers},
	doi = {10.1109/CVPR.1997.609375},
	abstract = {Grouping based on common motion, or “common fate” provides a powerful cue for segmenting image sequences. Recently a number of algorithms have been developed that successfully perform motion segmentation by assuming that the motion of each group can be described by a low dimensional parametric model (e.g. affine). Typically the assumption is that motion segments correspond to planar patches in 3D undergoing rigid motion. Here we develop an alternative approach, where the motion of each group is described by a smooth dense flow field and the stability of the estimation is ensured by means of a prior distribution on the class of flow fields. We present a variant of the EM algorithm that can segment image sequences by fitting multiple smooth flow fields to the spatiotemporal data. Using the method of Green's functions, we show how the estimation of a single smooth flow field can be performed in closed form, thus making the multiple model estimation computationally feasible. Furthermore, the number of models is estimated automatically using similar methods to those used in the parametric approach. We illustrate the algorithm's performance on synthetic and real image sequences},
	booktitle = {, 1997 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 1997. {Proceedings}},
	author = {Weiss, Y.},
	month = jun,
	year = {1997},
	keywords = {common fate, common motion, Computational modeling, Computer vision, Green's function methods, Green's functions, image segmentation, image sequences, motion estimation, motion segmentation, multiple model estimation, multiple smooth flow fields, nonparametric mixture estimation, Parametric statistics, real image sequences, rigid motion, spatiotemporal data, Spatiotemporal phenomena, Stability},
	pages = {520--526},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\MAI\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8h4pxrbr.default\\zotero\\storage\\RER4DPDB\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\MAI\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\8h4pxrbr.default\\zotero\\storage\\6HH89ZRK\\Weiss - 1997 - Smoothness in layers Motion segmentation using no.pdf:application/pdf}
}

@article{wang_representing_1994,
	title = {Representing moving images with layers},
	volume = {3},
	issn = {10577149},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=334981},
	doi = {10.1109/83.334981},
	number = {5},
	urldate = {2016-06-13},
	journal = {IEEE Transactions on Image Processing},
	author = {Wang, J.Y.A. and Adelson, E.H.},
	month = sep,
	year = {1994},
	pages = {625--638}
}

@inproceedings{forssen_maximally_2007,
	title = {Maximally {Stable} {Colour} {Regions} for {Recognition} and {Matching}},
	isbn = {978-1-4244-1179-5 978-1-4244-1180-1},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4270145},
	doi = {10.1109/CVPR.2007.383120},
	urldate = {2016-06-13},
	publisher = {IEEE},
	author = {Forssen, Per-Erik},
	month = jun,
	year = {2007},
	pages = {1--8}
}

@article{farabet_learning_2013,
	title = {Learning {Hierarchical} {Features} for {Scene} {Labeling}},
	volume = {35},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6338939},
	doi = {10.1109/TPAMI.2012.231},
	number = {8},
	urldate = {2016-06-13},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Farabet, Clement and Couprie, Camille and Najman, Laurent and LeCun, Yann},
	month = aug,
	year = {2013},
	pages = {1915--1929}
}

@inproceedings{zappella_motion_2008,
	address = {Amsterdam, The Netherlands, The Netherlands},
	title = {Motion {Segmentation}: {A} {Review}},
	isbn = {978-1-58603-925-7},
	shorttitle = {Motion {Segmentation}},
	url = {http://dl.acm.org/citation.cfm?id=1566899.1566953},
	abstract = {Motion segmentation is an essential process for many computer vision algorithms. During the last decade, a large amount of work has been trying to tackle this challenge, however, performances of most of them still fall far behind human perception. In this paper the motion segmentation problem is studied, analyzing and reviewing the most important and newest techniques. We propose a classification of all these techniques into different categories according to their main principle and features. Moreover, we point out their strengths and weaknesses and finally we suggest further research directions.},
	urldate = {2016-08-30},
	booktitle = {Proceedings of the 2008 {Conference} on {Artificial} {Intelligence} {Research} and {Development}: {Proceedings} of the 11th {International} {Conference} of the {Catalan} {Association} for {Artificial} {Intelligence}},
	publisher = {IOS Press},
	author = {Zappella, Luca and Lladó, Xavier and Salvi, Joaquim},
	year = {2008},
	keywords = {Computer vision, Motion analysis, motion segmentation},
	pages = {398--407}
}




@INPROCEEDINGS{4270260,
	author={A. Goh and R. Vidal},
	booktitle={2007 IEEE Conference on Computer Vision and Pattern Recognition},
	title={Segmenting Motions of Different Types by Unsupervised Manifold Clustering},
	year={2007},
	volume={},
	number={},
	pages={1-6},
	keywords={image motion analysis;image segmentation;image sequences;motion sequences;multiple affine;multiple motions segmentation;nonlinear dimensionality reduction;perspective views;unsupervised manifold clustering;Algorithm design and analysis;Analysis of variance;Clustering algorithms;Computer vision;Data analysis;Functional analysis;Motion segmentation;Null space;Testing;Vectors},
	doi={10.1109/CVPR.2007.383235},
	ISSN={1063-6919},
	month={June},}

@Article{Tomasi1992,
	author="Tomasi, Carlo
	and Kanade, Takeo",
	title="Shape and motion from image streams under orthography: a factorization method",
	journal="International Journal of Computer Vision",
	year="1992",
	month="Nov",
	day="01",
	volume="9",
	number="2",
	pages="137--154",
	abstract="Inferring scene geometry and camera motion from a stream of images is possible in principle, but is an ill-conditioned problem when the objects are distant with respect to their size. We have developed a factorization method that can overcome this difficulty by recovering shape and motion under orthography without computing depth as an intermediate step.",
	issn="1573-1405",
	doi="10.1007/BF00129684",
	url="https://doi.org/10.1007/BF00129684"
}



% Obstacle n Road detection

@INPROCEEDINGS{6957799,
	author={N. Bernini and M. Bertozzi and L. Castangia and M. Patander and M. Sabbatelli},
	booktitle={17th International IEEE Conference on Intelligent Transportation Systems (ITSC)},
	title={Real-time obstacle detection using stereo vision for autonomous ground vehicles: A survey},
	year={2014},
	volume={},
	number={},
	pages={873-878},
	keywords={object detection;road vehicles;stereo image processing;traffic engineering computing;2D sensor technologies;3D sensor technologies;autonomous ground vehicles;intelligent ground vehicle;real-time obstacle detection;stereo vision;Equations;Estimation;Mathematical model;Real-time systems;Roads;Stereo vision;Three-dimensional displays},
	doi={10.1109/ITSC.2014.6957799},
	ISSN={2153-0009},
	month={Oct},}

@ARTICLE{1364007,
	author={Yinghua He and Hong Wang and Bo Zhang},
	journal={IEEE Transactions on Intelligent Transportation Systems},
	title={Color-based road detection in urban traffic scenes},
	year={2004},
	volume={5},
	number={4},
	pages={309-318},
	keywords={Gaussian distribution;computational complexity;edge detection;image colour analysis;image segmentation;road vehicles;Gaussian distribution;autonomous driving;boundary estimation;color-based road detection;computational complexity;edge detection;edge image;urban traffic scenes;Analysis of variance;Detection algorithms;Distributed computing;Gaussian distribution;Image analysis;Image color analysis;Image edge detection;Layout;Roads;Surface fitting;65;Color-based segmentation;intelligent vehicle;road detection},
	doi={10.1109/TITS.2004.838221},
	ISSN={1524-9050},
	month={Dec},}

@inproceedings{oliveira_efficient_2016,
	title = {Efficient {Deep} {Models} for {Monocular} {Road} {Segmentation}.},
	url = {https://lmb.informatik.uni-freiburg.de/Publications/2016/OB16b/},
	urldate = {2017-04-23},
	author = {Oliveira, Gabriel Leivas and Burgard, W. and Brox, Thomas},
	year = {2016}
}

@ARTICLE{8352801,
	author={A. Dairi and F. Harrou and Y. Sun and M. Senouci},
	journal={IEEE Sensors Journal},
	title={Obstacle Detection for Intelligent Transportation Systems Using Deep Stacked Autoencoder and $k$ -Nearest Neighbor Scheme},
	year={2018},
	volume={18},
	number={12},
	pages={5122-5132},
	keywords={Clustering algorithms;Kernel;Machine learning;Machine learning algorithms;Partitioning algorithms;Roads;Sensors;Obstacle detection;autonomous vehicles;clustering algorithms;deep learning;intelligent transportation systems},
	doi={10.1109/JSEN.2018.2831082},
	ISSN={1530-437X},
	month={June},}


@ARTICLE{7600385,
	author={V. D. Nguyen and H. Van Nguyen and D. T. Tran and S. J. Lee and J. W. Jeon},
	journal={IEEE Transactions on Intelligent Transportation Systems},
	title={Learning Framework for Robust Obstacle Detection, Recognition, and Tracking},
	year={2017},
	volume={18},
	number={6},
	pages={1633-1646},
	keywords={learning (artificial intelligence);object recognition;pedestrians;adaptive U-V disparity algorithm;deep learning approach;detected pedestrian tracking;detected vehicle tracking;driver assistance systems;driving conditions;learning framework;robust obstacle detection;robust obstacle recognition;robust obstacle tracking;robust on-road vehicle detection;robust on-road vehicle recognition;robust on-road vehicle tracking;robust pedestrian detection;robust pedestrian recognition;robust pedestrian tracking;Cameras;Machine learning;Neural networks;Roads;Robustness;Training;Vehicles;Deep learning;unsupervised learning;vehicle and pedestrian detection},
	doi={10.1109/TITS.2016.2614818},
	ISSN={1524-9050},
	month={June},}